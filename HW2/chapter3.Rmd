\section{Puppet Markov Chain}

First of all let's define the Markov Chain that we want to analyze:

\begin{figure}
   \includegraphics[width=0.475\textwidth]{images/markov.png}
   \hfill
   \includegraphics[width=0.475\textwidth]{images/markov.png}
   \caption{On the left the graphical reppresentaion of our Markov Chain and on the right its transition matrix}
\end{figure}



First of all we define a s4 object constructor for Markov Chains and than delcare an puppet markov chain:

```{r, include = TRUE}
#Markov Chains Constructor

setClass("markov_chain",
         slots = list(state_space="numeric",
                      initial_state="numeric",
                      chain_size="numeric",
                      transition_matrix="matrix"))

setGeneric("MCSimulator", function(object) {
  standardGeneric("MCSimulator")
})

setGeneric("set_initial_state", function(object, init_state ) {
  standardGeneric("set_initial_state")
})
```

\subsection{Markov Chain Simulation}

We now define a function that would allows us to simulate our chain

```{r, include = TRUE}
#Markov Chain Simulator

setMethod("MCSimulator", signature("markov_chain"), function(object){
  markov_chain <- c(vector(), 1:(object@chain_size-1))
  markov_chain[1] = object@initial_state
  
  for(t in 1:(object@chain_size)){
    markov_chain[t+1] <- sample(object@state_space, size = (object@chain_size), prob=object@transition_matrix[markov_chain[t],], replace = TRUE)
  }
  return(markov_chain)
})

setMethod("set_initial_state", signature("markov_chain", "numeric"), function(object, init_state){
  object@initial_state <- init_state
  return(object)})
```

Now that the we have all the necessary elements we can simulate our markov chain:

```{r, include=FALSE}

puppet_markov_chain <- new("markov_chain",
                           state_space = c(1,2,3),
                           initial_state = 1,
                           chain_size = 1000,
                           transition_matrix = matrix(c(0, 1/2, 1/2, 5/8, 1/8, 1/4, 2/3, 1/3, 0), nrow = 3, ncol = 3)
                           )



puppet_markov_chain

markov_simulation <- MCSimulator(puppet_markov_chain)

plot(MCSimulator(puppet_markov_chain), ylim=c(0,4), ylab = "Chain State", xlab = "Time", main = "Simulated Markov Chain")
```
\subsection{States Empirical Relative Frequency}

At this point is pretty straight forward to printthe empirical relative frequency of the three states
```{r, include=TRUE}
library(HistogramTools)
PlotRelativeFrequency(hist(markov_simulation, plot = F), main="State")
```


\subsection{Simulation Repeatition}

At this point we compute the simulation by calling


\subsection{Invariant Distribution $\pi$ (closed form)}
We can compute the invariant distribution by definition, hene:

\begin{equation}
\pi = \left(\begin{array}{c} \pi_1\\ \pi_2\\ \pi_3 \end{array}\right) = (\pi_1 \pi_2 \pi_3) \cdot
\left(\begin{array}{c c c}
0 & \frac{1}{2} & \frac{1}{2} \\
\frac{5}{8} & \frac{1}{8} & \frac{1}{4} \\
\frac{2}{3} & \frac{1}{3} & 0 \\ 
\end{array})\right) = \pi P
\end{equation}

Which is subject to the costraint of a probability measure, indeed $\pi_1 + \pi_2 + \pi_3 = 1$ which 

at this point the only thing that we have to do is to solve this system by substituting the second equation with  the constraint since is linear combination of the other equations:

```{r, include= TRUE}
library(limSolve)
A = matrix(c(-1, 1/2, 1/2, 1, 5/8, -7/8, 1/4, 1, 2/3, 1/3, -1,1), nrow = 4, ncol = 3)
b = c(0,0,0,1)
analytical_invariant_distribution <- Solve(A,b)
analytical_invariant_distribution
```
\subsection{Evaluation}

Now that we have the true analytical solution of our Markov Chain we want to check if our simulation is indeed a good approximation of this value. In order to compare those values we compare the two 
gen
```{r, include = TRUE}
genziana <- as.vector(table(markov_simulation)/sum(markov_simulation))
library(plotrix)
l <- list(analytical_invariant_distribution, markov_simulation)
multhist(l, beside = TRUE, freq = FALSE)

```

\subsection{Initial State Independecy}

If we change the initial state, since the Markov chain is irreducible and positive recurrent, we will not have any sensible difference in the final outcome for the ergodic theorem. This is can be experimentally proven by simulating the markov chain with different starting point for 500 times with different values in $X_{1000}$

Once again at this point we declare a new object Markov Chain:

```{r, include = TRUE, eval = FALSE}
puppet_markov_chain = set_initial_state(puppet_markov_chain, 2)
x_1000 <- c()
for(i in 1:500){
  mc <- MCSimulator(puppet_markov_chain)
  x_1000[i] <- mc[1000]
}

l <- list(analytical_invariant_distribution, markov_simulation)
multhist(l, beside = TRUE, freq = FALSE)

```
