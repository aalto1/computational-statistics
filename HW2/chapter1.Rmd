\section{Markov Chains Essentials}
Markov Process are sthocastics process which are usually defined as a collection of random variables. Markov Chains are useful to model random process which has a short memory dependence.

We can have four types of Markov Chains:

\begin{tabular}{|p{4cm}||p{4cm}|p{4cm}| }
 \hline
 \multicolumn{3}{|c|}{Types of Markov Chains} \\
 \hline
 Time/State-Space & Countable State Space & General State Space\\
 \hline
 Discrete-Time & MC on a finite state space & MC on a general state space\\ 
 Continuos-Time & Markov Process & Stochastic Process w/ Markov Property\\ [1ex] 
 \hline
\end{tabular}

In this case we are instrested in defining the probability law of Markov Chains on a generals state space. Let $t \in \{0,1,2,...\}$ be the index of the process and $S \subset \!R^k$ the general state space of states:

\begin{enumerate}
\item $\mu \rightarrow $ initial distribution at time t = 0
\item Transition Kernel $K_t(x,A) = Pr\{X_{t+1} \in A | X_t = x \}$ for each $t = \{1,2,...\}$
\end{enumerate}

Where the transition kernel is a function $K(\cdot,\cdot) : S \times \mathcal{B}(\mathcal{S})\rightarrow [0,1]$

\begin{itemize}
\item $\forall x \in \mathcal{S}: K(x,\cdot) $ is a probability measure
\item $\forall A \in \mathcal{B}(S) : K(\cdot,A)$ is measurable
\end{itemize}


\subsection{Markov Chain as an approximation tool}
Markov Chains have several properties among which \textbf{Invariant Measure} and \textbf{Stationarity} at steady-state. More formally given a finite Markov Chain $X_t,t \in \mathcal{T}$ which is irreducible and poistive recurrent than after t stpes I get a random  value: $\theta_t \sim P^t_y(\cdot) = K^t(y,\cdot).$ This is true thanks to the ergodic theorem, which holds in under the previous properties.

In the end we obtain $P_y^t(\cdot)\rightarrow P^{\infty}_y=\pi(\cdot)$ or more specifically,

\begin{equation}
\hat{I} = \frac{1}{t}\sum^{T_0+t}_{i=T_0} h(\theta_i) \rightarrow E_{\pi}[h(\theta)] = I \quad for \ t  \rightarrow \infty
\end{equation}

Given a suitable Markov Chain defined by a Markov Kernel $K(x,\cdot)$ depends on the possibility of finding a suitable \pi such that $X_n \sim \pi \Rightarrow X_{n+1} \sim \pi$

Thus the subsequent issue that we have to analyze how is possible to generate a stationary distribution from a Markov Chain.
This requires a useful property defined as \textbf{Detailed Balance Condition} which than implies that the Markov Chain is reversible $Pr_{\pi}\{X_t \in A, X_{t+1} \in B\} = Pr\{{X_{t+1} \in A, X_t\in B}\}$ which is equivalent to $\pi(x)q(x,y) = \pi(y)q(y,x)$ given this backword transition 













